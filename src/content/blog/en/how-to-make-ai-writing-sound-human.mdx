Your LinkedIn post gets 50 likes, a few comments, and then someone writes: "Solid content. Is this ChatGPT?"

You edited the draft. You changed a few words. You thought it sounded fine. But AI writing has patterns that aren't obvious to the person who wrote it. They're obvious to everyone else.

## The patterns nobody talks about

Most advice about humanizing AI text focuses on the basics: don't use "delve," avoid "it's worth noting," break up long paragraphs. That's surface-level. Here's what actually gives you away.

### Frequency, not vocabulary

The word "moreover" isn't suspicious on its own. But AI uses it 8-10 times more often than human writers. "Furthermore" runs 7-9x higher. "Crucial" appears 6-8x more in AI text.

Your readers don't consciously count these words. Their brains do it automatically. When "moreover" shows up three times in 500 words, something feels off even if the reader can't explain why.

### The three-item list problem

Count the bullet points in your last AI-generated draft. You'll find lists of exactly three items everywhere. "Fast, reliable, and scalable." "Planning, execution, and measurement." "Research, write, and publish."

Human writers use two items, four, five. They don't default to three. When 70% of your lists have exactly three elements, you've created a mathematical fingerprint.

### Structure over substance

AI produces paragraphs of remarkably uniform length. Measure the word count: 22 words, 24 words, 21 words, 23 words. Human writing swings wildly. A five-word sentence followed by a forty-word thought, then a medium paragraph. The standard deviation in sentence length is one of the most reliable detection signals.

### Model-specific signatures

Different AI models leave different fingerprints. ChatGPT loves em dashes, "it's worth noting," and immediate structured lists. Claude tends to be more conversational but overuses formal connectors in professional mode. Gemini oversimplifies and chops sentences short.

If your text has em dashes without spaces and "it's important to note" in the same paragraph, that's a ChatGPT double tell with over 95% confidence.

## Italian has entirely different rules

If you write in Italian, everything changes. English AI patterns don't transfer.

The biggest tell in Italian AI text? "Inoltre." It appears 5-8 times more frequently in AI output than in human writing. Followed by "tuttavia" (4-6x), "nonostante" (3-5x), and the ChatGPT hallmark "è interessante notare che."

Then there's VARIATIO. Italian style mandates that you never repeat the same word within a close range. You write "Milano" once, then switch to "il capoluogo lombardo," then "la metropoli," then "la città meneghina." AI models trained primarily on English data don't know this rule exists. They'll write "Milano" four times in two paragraphs and an Italian reader will immediately sense something artificial.

Italian typography tells are different too. Capitals after colons? AI does it consistently. Italians don't. Title Case in headings like "Come Ottimizzare La Tua Strategia"? That's an English convention. The correct Italian form is "Come ottimizzare la tua strategia."

## A practical framework

Here's how to catch these patterns in your own writing:

**Check your connector density.** Search for "moreover," "furthermore," "additionally" in English. For Italian, search "inoltre," "tuttavia," "nonostante." If any appears more than once per 500 words, replace or remove.

**Break the triple.** Find every list with exactly three items. Change at least half to two, four, or five items.

**Vary your rhythm.** After editing, look at paragraph length. If they're all roughly equal, split one into a single sentence and combine two others into a longer thought.

**Read the opening.** If it starts with "In today's..." or any variation of "In an era of..." delete the entire first sentence. Start with the second one.

**Kill the conclusion formula.** "In conclusion," "in summary," "to wrap up." If you need these words, your conclusion doesn't stand on its own. Rewrite it.

## When you don't have time

This framework works. It also takes 15-20 minutes per piece if you do it manually.

HumanWriter automates the process. It maps over 200 patterns per language across four severity tiers, runs your text against all of them in seconds, and returns a report with every flag explained and an alternative ready. It catches the patterns you'd never spot visually: frequency distributions, sentence length uniformity, model-specific signatures.

It also handles the Italian-English divide. The databases are separate, built specifically for each language, because a pattern that's normal in an English academic paper can be a red flag in an Italian LinkedIn post.

You write with AI, run HumanWriter, and publish text that sounds like it came from you. Not from a model.
